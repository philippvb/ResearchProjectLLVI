{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "sys.path.append('/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BasicExample')\n",
    "sys.path.append('/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI')\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from laplace import Laplace\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from src.weight_distribution.Full import FullCovariance\n",
    "from src.weight_distribution.Diagonal import Diagonal\n",
    "from src.network.Classification import LLVIClassification\n",
    "from src.network import PredictApprox, LikApprox\n",
    "from PyTorch_CIFAR10.cifar10_models.resnet import resnet18, resnet34, resnet18VI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "dataset_size = 1024\n",
    "data_dir = \"/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BasicExample/datasets/Classification/CIFAR10\"\n",
    "dataset = torchvision.datasets.CIFAR10(data_dir, train=True, download=False,\n",
    "                            transform=torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "            ]\n",
    "        ))\n",
    "dataset, _  = torch.utils.data.random_split(dataset, [dataset_size, len(dataset) - dataset_size])\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size_train, shuffle=True)\n",
    "n_datapoints = batch_size_train * len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_test = 1000 # whole dataset\n",
    "test_dataset_size = 1000\n",
    "data_dir = \"/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BasicExample/datasets/Classification/CIFAR10\"\n",
    "test_dataset = torchvision.datasets.CIFAR10(data_dir, train=False, download=False,\n",
    "                            transform=torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "            ]\n",
    "        ))\n",
    "test_dataset, _  = torch.utils.data.random_split(test_dataset, [test_dataset_size, len(test_dataset) - test_dataset_size])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)\n",
    "n_test_datapoints = batch_size_test * len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "feature_dim = 50\n",
    "out_dim=10\n",
    "weight_decay = 1e-3\n",
    "lr = 1e-3\n",
    "base_train_epochs = 1\n",
    "\n",
    "# VI parameters\n",
    "tau = 1\n",
    "vi_train_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_model = resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP accuracy 0.9229999780654907\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_loader:\n",
    "    predictions = laplace_model(X_batch)\n",
    "    pred_test = torch.argmax(predictions, dim=1)\n",
    "    print(\"MAP accuracy\", torch.mean((pred_test == y_batch).float()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define laplace\n",
    "la = Laplace(laplace_model, \"classification\",\n",
    "    subset_of_weights=\"last_layer\", hessian_structure=\"diag\",\n",
    "    prior_precision=1) # prior precision is set to wdecay\n",
    "la.fit(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Laplace 0.9079999923706055\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_loader:\n",
    "    predictions = la(X_batch, link_approx='mc', n_samples=100)\n",
    "    pred_test = torch.argmax(predictions, dim=1)\n",
    "    print(\"Accuracy with Laplace\", torch.mean((pred_test == y_batch).float()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with VI before Training 0.902999997138977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prediction_loss:1.38 kl_loss:1.54: 100%|██████████| 2/2 [00:49<00:00, 24.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with VI after Training 0.9100000262260437\n"
     ]
    }
   ],
   "source": [
    "dist = Diagonal(512, 10, lr=lr)\n",
    "# dist.update_var(torch.reshape(la.posterior_variance[:-10], (512, 10)))\n",
    "dist.update_mean(torch.t(laplace_model.fc.weight))\n",
    "\n",
    "\n",
    "vi_model = resnet18VI(pretrained=True)\n",
    "\n",
    "prior_log_var = 1\n",
    "net = LLVIClassification(512, 10, vi_model, dist, prior_log_var=prior_log_var, optimizer_type=torch.optim.Adam,\n",
    "tau=tau, lr=lr)\n",
    "\n",
    "for X_batch, y_batch in test_loader:\n",
    "    predictions = net(X_batch, method=PredictApprox.MONTECARLO, samples=100)\n",
    "    pred_test = torch.argmax(predictions, dim=1)\n",
    "    print(\"Accuracy with VI before Training\", torch.mean((pred_test == y_batch).float()).item())\n",
    "\n",
    "net.train_ll_only(train_loader, epochs=vi_train_epochs, n_datapoints=n_datapoints, samples=10, method=LikApprox.MONTECARLO)\n",
    "\n",
    "for X_batch, y_batch in test_loader:\n",
    "    predictions = net(X_batch, method=PredictApprox.MONTECARLO, samples=100)\n",
    "    pred_test = torch.argmax(predictions, dim=1)\n",
    "    print(\"Accuracy with VI after Training\", torch.mean((pred_test == y_batch).float()).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_confidence(predict_fun, test_loader, ood_test_loader):\n",
    "    confidence_batch = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = predict_fun(data)\n",
    "            pred, _ = torch.max(output, dim=1) # confidence in choice\n",
    "            confidence_batch.append(torch.mean(pred))\n",
    "        print(f\"The mean confidence for in distribution data is: {sum(confidence_batch)/len(confidence_batch)}\")\n",
    "\n",
    "    ood_confidence_batch = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in ood_test_loader:\n",
    "            output = predict_fun(data)\n",
    "            pred, _ = torch.max(output, dim=1) # confidence in choice\n",
    "            ood_confidence_batch.append(torch.mean(pred))\n",
    "        print(f\"The mean confidence for out-of distribution data is: {sum(ood_confidence_batch)/len(ood_confidence_batch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_samples = 100\n",
    "la_predict_fun = lambda x: la(x, link_approx='mc', n_samples=predict_samples)\n",
    "vi_predict_fun = lambda x: net(x, method=PredictApprox.MONTECARLO, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean confidence for in distribution data is: 0.8469984531402588\n",
      "The mean confidence for out-of distribution data is: 0.6441346406936646\n"
     ]
    }
   ],
   "source": [
    "test_confidence(la_predict_fun, test_loader, ood_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean confidence for in distribution data is: 0.8522112369537354\n",
      "The mean confidence for out-of distribution data is: 0.6150723695755005\n"
     ]
    }
   ],
   "source": [
    "test_confidence(vi_predict_fun, test_loader, ood_test_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cabe5e2adc12bc55fec3b05872858fd36eca333f32d669b1230866c442273ae7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
