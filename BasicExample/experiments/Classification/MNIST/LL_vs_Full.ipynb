{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BasicExample\")\n",
    "\n",
    "from src.network import LikApprox\n",
    "from src.network import PredictApprox\n",
    "from src.weight_distribution.Diagonal import Diagonal\n",
    "from src.weight_distribution.Full import FullCovariance\n",
    "from src.network.Classification import LLVIClassification\n",
    "\n",
    "sys.path.append(\"/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI\")\n",
    "from BNN_Comparison.TyXe import tyxe\n",
    "from pyro import distributions as pyro_dist\n",
    "import pyro\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.size\": 14,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/DeepLearning/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1635217266490/work/torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_test = 32\n",
    "filepath = \"/Users/philippvonbachmann/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BasicExample/datasets/Classification\"\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(filepath, train=True, download=False,\n",
    "                            transform=torchvision.transforms.Compose([\n",
    "                              torchvision.transforms.ToTensor(),\n",
    "                              torchvision.transforms.Normalize(\n",
    "                                (0.1307,), (0.3081,))\n",
    "                            ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "n_datapoints = batch_size_train * len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "torchvision.datasets.MNIST(filepath, train=False, download=False,\n",
    "                            transform=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize(\n",
    "                                (0.1307,), (0.3081,))\n",
    "                            ])),\n",
    "batch_size=batch_size_test, shuffle=True)\n",
    "n_test_datapoints = batch_size_test * len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_cols = [\"Epoch time\", \"NLL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochTimeStamp:\n",
    "    def __init__(self):\n",
    "        self.epoch_start_time = datetime.now()\n",
    "    \n",
    "    def get_delta(self):\n",
    "        return (datetime.now() - self.epoch_start_time).total_seconds()\n",
    "\n",
    "    def update(self):\n",
    "        self.epoch_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_dim=10, optimizer=optim.Adam, **optim_kwargs):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 50)\n",
    "        self.fc3 = nn.Linear(50, out_dim, bias=False)\n",
    "        self.optimizer: optim = optimizer(self.parameters(), **optim_kwargs)\n",
    "        self.nonll = torch.sigmoid # nonlinear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.nonll(self.conv1(x)))\n",
    "        x = self.pool(self.nonll(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.nonll(self.fc1(x))\n",
    "        x = self.nonll(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "class VICNN(nn.Module):\n",
    "    def __init__(self, feature_dim=50, optimizer=optim.Adam, **optim_kwargs):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, feature_dim)\n",
    "        self.optimizer: optim = optimizer(self.parameters(), **optim_kwargs)\n",
    "        self.nonll = torch.sigmoid # nonlinear layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.nonll(self.conv1(x)))\n",
    "        x = self.pool(self.nonll(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.nonll(self.fc1(x))\n",
    "        x = self.nonll(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general parameters\n",
    "feature_dim = 50\n",
    "out_dim = 10\n",
    "weight_decay = 1e-3\n",
    "lr = 1e-3\n",
    "tau = 1\n",
    "prior_log_var = math.log(1/(weight_decay * n_datapoints))\n",
    "epochs=5\n",
    "train_samples = 10\n",
    "test_samples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last-layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3)\n",
    "ll_vifeature_extractor = VICNN(lr=lr, weight_decay=weight_decay, feature_dim=feature_dim)\n",
    "\n",
    "dist = Diagonal(feature_dim, out_dim, lr=lr, init_log_var=-1)\n",
    "\n",
    "llvi_net = LLVIClassification(feature_dim, out_dim, ll_vifeature_extractor, dist, prior_log_var=prior_log_var,\n",
    "tau=tau, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def callback_fun(model, validation_set, n_datapoints, tracking_list, epoch_time_stamp: EpochTimeStamp):\n",
    "    epoch_time = epoch_time_stamp.get_delta() # get epoch time\n",
    "    total_loss = 0\n",
    "    loss_metric = torch.nn.NLLLoss(reduction=\"mean\")\n",
    "    for data, target in validation_set:\n",
    "        prediction = model(data, method=PredictApprox.MONTECARLO, samples=test_samples)\n",
    "        prediction = torch.log(prediction) # need logsoftmax for nll loss\n",
    "        total_loss += loss_metric(prediction, target).item()\n",
    "    total_loss/= n_datapoints\n",
    "    \n",
    "    tracking_list.loc[len(tracking_list)] = [epoch_time, total_loss]\n",
    "    epoch_time_stamp.update() # update start time for new epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prediction_loss:0.16 kl_loss:0.39: 100%|██████████| 5/5 [01:22<00:00, 16.55s/it]\n"
     ]
    }
   ],
   "source": [
    "ll_tracking = pd.DataFrame(columns=tracking_cols)\n",
    "ll_epoch_start = EpochTimeStamp()\n",
    "llvi_validation_fun = lambda x: callback_fun(llvi_net, test_loader, n_test_datapoints, ll_tracking, ll_epoch_start)\n",
    "llvi_net.train_model(train_loader, epochs=epochs, n_datapoints=n_datapoints, method=LikApprox.MONTECARLO, callback=llvi_validation_fun, samples=train_samples);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "full_net = CNN(lr=lr, weight_decay=weight_decay, out_dim=out_dim)\n",
    "prior = tyxe.priors.IIDPrior(pyro_dist.Normal(0, math.exp(prior_log_var)))\n",
    "kl_div_scaling_factor=1/tau\n",
    "likelihood = tyxe.likelihoods.Categorical(n_datapoints * kl_div_scaling_factor)\n",
    "inference = tyxe.guides.AutoNormal\n",
    "full_bnn = tyxe.VariationalBNN(full_net, prior, likelihood, inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vi_tracking = pd.DataFrame(columns=tracking_cols)\n",
    "\n",
    "@torch.no_grad()\n",
    "def full_layer_val_fun(_, epoch, elbo, epoch_time_stamp: EpochTimeStamp):\n",
    "    epoch_time = epoch_time_stamp.get_delta()\n",
    "    print(f\"Epoch {epoch}, ELBO loss {elbo} \", end=\"\\r\")\n",
    "    total_loss = 0\n",
    "    loss_metric = torch.nn.NLLLoss(reduction=\"mean\")\n",
    "    for data, target in test_loader:\n",
    "        prediction = full_bnn.predict(data, num_predictions=test_samples)\n",
    "        prediction = torch.log_softmax(prediction, dim=-1)\n",
    "        total_loss += loss_metric(prediction, target).item()\n",
    "    total_loss/= n_test_datapoints\n",
    "    full_vi_tracking.loc[len(full_vi_tracking)] = [epoch_time, total_loss]\n",
    "    epoch_time_stamp.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, ELBO loss 142769.31157583313 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/07/l3_khs3x2n1c8glbln1c071h0000gn/T/ipykernel_39867/3189302099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfull_layer_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfull_layer_val_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_epoch_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtyxe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_reparameterization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfull_bnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_layer_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_particles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/University/WiSe2122/ResearchProject/ResearchProjectLLVI/BNN_Comparison/TyXe/tyxe/bnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_loader, optim, num_epochs, callback, num_particles, closed_form_kl, device)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mnum_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0melbo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;31m# the callback can stop training by returning True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DeepLearning/lib/python3.9/site-packages/pyro_ppl-1.4.0-py3.9.egg/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DeepLearning/lib/python3.9/site-packages/pyro_ppl-1.4.0-py3.9.egg/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrainable_params\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'requires_grad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0msurrogate_loss_particle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mwarn_if_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DeepLearning/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/DeepLearning/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optim = pyro.optim.Adam({\"lr\": 1e-3})\n",
    "epochs=5\n",
    "full_epoch_start = EpochTimeStamp()\n",
    "full_layer_callback = lambda x,y,z: full_layer_val_fun(x,y,z, full_epoch_start)\n",
    "with tyxe.poutine.local_reparameterization():\n",
    "    full_bnn.fit(train_loader, optim, num_epochs=epochs, callback=full_layer_callback, num_particles=train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.plot(ll_tracking[\"Epoch time\"].cumsum(), ll_tracking[\"NLL\"], label=\"Last-Layer\")\n",
    "axs.plot(full_vi_tracking[\"Epoch time\"].cumsum(), full_vi_tracking[\"NLL\"], label=\"Full-Layer\")\n",
    "axs.legend()\n",
    "axs.set_xlabel(\"Time (s)\")\n",
    "axs.set_ylabel(\"NLL\")\n",
    "axs.set_ylim(0, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE vs Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS20lEQVR4nO3dz28jaV7H8c/XSXoyOzuLJyGjATVi2n2ZAa2EHPeJ4zgHJDjhzJyRIBHae2ebC9pTk/AXxLP/QHdy2wMSMWcOcQwSYgcOsUCK0EK2054FZkL3JF8OfuxUKuVficvlJO+X1EpVPVXlb55O6uOqcj0xdxcA4H7LZV0AACB7hAEAgDAAABAGAAARBgAAEQYAAKUUBmZWMbOyma0ltOXNrBjW2Ywsf21me2b2NI2aAAC9jT0MzKwiSe5eC/Pl2CqfSyq5+25o7wTGqruvuPvWuGsCAPSXxpnBE0nNMN2UVIw2unvV3aththBZN29mhRTqAQAMMJvCPvOx+cWklcKB/6RzBiFpQdKJmW27+3rC+muS1iTpvffeW/7kk0/GVzEA3AMHBwe/dPelpLY0wqCl9oF9kEr0oN85WzCzlplVOpeRYu1VSSqVSl6v18dXMQDcA2b2773a0giDfV2cHRQk7SUUVOncGzCzoqSSpLq7N1KoBwAwwNjvGYR39IVw4zgfuZG8F76WJW2a2YGZHah9FvEytFUi+wAATIjdxlFLuUwEAKMzswN3LyW1pXGZCACu5e3btzo6OtLp6WnWpdxq8/Pzevjwoebm5obehjAAMDWOjo70/vvv6+OPP5aZZV3OreTuevXqlY6OjvTo0aOht2M4CgBT4/T0VIuLiwTBDZiZFhcXRz67IgwATBWC4Oau04eEAQAEjUZDKysrN9pHq9VSrVa7snwc+04TYQAAY3RycqLt7e2syxgZYQAAQ1hdXdXy8rKWl5fVaLSfj221Wt3lq6urkqSNjQ3VajXt7g7/uFR035999ll3/7VaTevr7YEa1tfX9fjx40uvv7u7q42NDS0vL6vZbPbc/zD4NBGAqfSTn/2zfv4fvxrrPn/nN3+gv/yj3x15u0ajoUKhoJ2dHTUaDT1//lw7OzuqVqt68uSJdnZ2tLW1pWazqc3NTW1sbKhSqVxr3z/60Y/04sULFYtFbW9v69mzZ9rd3dXJyYkODw/VbDa1srKiw8NDSe1A6EzfBGEAAAMUi0Xl83lVq1Xt7Owon89LksrlcveMoFKpqFAojPwOPb7vDz/8sHvPodFoqFgs6sWLF2o2m93XajabarVa3RrGgTAAMJWu8w4+LbVaTRsbG3r27Jk2Nja69wSKxaIODg5UrVa1srKi7e1tFQoXI/F3DvCFQqF7uWeYfS8sLKharV460G9ubiYe+DvBdFPcMwCAAfb29rS+vq5KpXLpXXnn/sDTp0+1vr7evZbfsba2pr29vb43lJP2vbq6qvX19W6AdIJGap8VLC8vj/17JAwAIKJWq3Vv5nZu1q6vr2tnZ6d7rb5er3eXd27g7u/va21tTYVCQY1GI/EG8rD7/uijj5TP51Ustv82WLlcVqFQ0PLyslZWVvTll1+O/ftmoDoAU+Orr77Sp59+mnUZmdvd3dX+/r42NzcHr9xDUl8yUB0A3BKdj4seHBxM9HW5TAQAU6RSqejw8HBsN4aHRRgAAAgDAABhAAAQYQAAXa1WS2amx48fd//1elhMat/s3dra6n6NmvZRSuP4NBEARHSeKr5vODMAgAHi7/xv+gRwfATU1dXVTEYqjeLMAMB0+psfS7/4p/Hu86MfSn/wV31XaTQalw72437aN2kE1C+++CKTkUqjCAMAiEi6TDTOd+BJI6CWy2U9f/5c0mRHKo0iDABMpwHv4LPSOSAnue4opfl8PpORSqO4ZwAAA+Tz+e5lmZcvX/Zc77qjlErKZKTSKMIAAAYol8uXrtuXSoljvV0xygio5XJ54iOVRjFqKYCpcZ9HLR3HSKVRjFoKALdMViOVRnGZCAAyltVIpVGEAYCpchsvXU+b6/QhYQBgaszPz+vVq1cEwg24u169eqX5+fmRtuOeAYCp8fDhQx0dHen4+DjrUm61+fl5PXz4cKRtCAMAU2Nubk6PHj3Kuox7ictEAADCAABAGAAAlNI9AzOrSGpJKrh7NdaWl1QI/564+8agbQAA6Rr7mUE4qMvda2E+PuTe55JK7r4b2teG2AYAkKI0LhM9kdQZ/LspqRhtdPdq5J1/IazTdxupGxp1M6vzsTMAGK80wiAfm19MWsnMCpJOwtnAwG1CiJTcvbS0tDSOOgEAQRph0JK0MMR6FXfv/PWHYbcBAKQgjTDY18U7/YKkvfgKZlZx960wXRxmGwBAesYeBuHGcCHcBM5Hbgrvha9lSZtmdmBmB5IWem0DAJgM/rgNANwT/f64DQ+dAQAIAwAAYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAAAQYQAAEGEAABBhAABQSmFgZhUzK5vZWp/2vdiy12a2Z2ZP06gJANDb2MPAzCqS5O61MF+Or+Puuwmbrrr7irtvjbsmAEB/aZwZPJHUDNNNScUht8ubWSGFegAAA6QRBvnY/OKQ2y1IOjGz7aRGM1szs7qZ1Y+Pj29SHwAgJo0waKl9YB+Ju1fdvSWp1bnUlNBecvfS0tLSzasEAHSlEQb7ujg7KEja671qW3jXP+zlJADAmI09DMLN4UK4cZyP3EjuhkJoK0XOAF6G5ZXIPgAAE2LunnUNIyuVSl6v17MuAwBuFTM7cPdSUhsPnQEACAMAAGEAABBhAAAQYQAAEGEAABBhAAAQYQAA0DXDwMx+b8x1AAAydN0zgy/HWgUAIFPXDQMbaxUAgExdNwxu34BGAICeZns1mNnfKvmgbxr+r5cBAG6BnmEgaWNiVQAAMtUzDNz9H3q18WkiALhb+DQRAIBPEwEA+DQRAEB8mggAID5NBABQ/zBYHrBtz08bAQBul35h8EHCMpf0F+HrT1OpCAAwcf2eM/jr6LyZ/bGkTUnP420AgNut35mBpO4DZj+VdChp2d2/TrsoAMBk9fs00Q/UPhMoSfpTd//HSRUFAJisfmcGLUmvJf2dpHWzy8+Zufufp1cWAGCSbvJpIgDAHXGtgeoAAHfLdYejAADcIYQBAIAwAAAQBgAAEQYAABEGAAARBgAAEQYAAKUUBmZWMbOyma31ad8bZRsAQHrGHgZmVpEkd6+F+XJ8HXffHXUbAEB60jgzeCKpGaabGu7vJQ/cxszWzKxuZvXj4+OxFAoAaEsjDPKx+cVxbOPuVXcvuXtpaWnpmqUBAJKkEQYtSQsT2AYAMCZphMG+Lt7pFyTt9V71RtsAAMZk7GEQbg4Xwk3gfOSmcPcAH9pKkRvHidsAACbD3D3rGkZWKpW8Xq9nXQYA3CpmduDupaQ2HjoDABAGAADCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAACDCAAAgwgAAIMIAAKCUwsDMKmZWNrO1YdvN7LWZ7ZnZ0zRqAgD0NvYwMLOKJLl7LcyXh2xfdfcVd98ad00AgP7SODN4IqkZppuSikO2582skEI9AIAB0giDfGx+ccj2BUknZradtFMzWzOzupnVj4+Pb1wkAOBCGmHQUvvAPlK7u1fdvSWp1bmUlNBecvfS0tLSmEoFAEjphMG+Lt79FyTtDWoP7/rjl5MAABMy9jBw911JhXBjOB+5UbzXp/1lWKcSWQcAMCHm7lnXMLJSqeT1ej3rMgDgVjGzA3cvJbXx0BkAgDAAABAGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAAEQYAABEGAAARBgAASbNZFzBJ//KLX+nvD1/p3bkZvftg5tLX+eiyMP3ObE5mlnXZAJC6exUG+//2Wj/52c+HXt9M3XCIh8X8gxm9O5fT9x7MttvmZvTug1zPYOkVPPNzM5rJETgAsnWvwuCL0m/pD3/4G/r27Vn735sznb490zdv2vOnYVmn/TQy/c2by+1ff/tW//n15XW/eXums3Mfua4Hszl9Lxo0icExQvBcCa0Zzc1wRRBAb/cqDB7M5vRg9oE+SGn/7q63Z943WAYHz7m+ffNdWPc7vfrfN1fWffPd+ci1zebsSljMzyWdsVwOnfm5nGZyJjPTjJlyJuXMlMu1pzttOZNmLDKds0vr5SzMx7fprGemXO7qejkzWXy9WA05s7BPhRrb01ziA4Z3r8IgbWamB7OmB7M5/dq7c6m9ztm5Xzqz+bZP8FwJnUvz5zp9c6b/+u/TsK/zS/u67RJDIxYuZqaZaAjlBq/XDsZegXTRFg88iwVXUjheBF6Yj4VcLoTcTO5iOherLWmfM5HXvxy6F6/TK2i7rx95zWjo5q7UM+h7DvV0alb7kqwkmexi2trzF9Pt/V9an8AfG8LgFprJmb7/zqy+/056/33urv/77lzfvjnTubvO3OWu9vR5e/rs3HXurvOwPNrWme62nV9e79wVll2s5+F1om2X1vPIeucJ64XXSVrP4/V0601Y70oNkfWu7Ls9/93Zeaix3dauJfb9xvoh3ofd/Uf7MNJ2HtbHVdGwkNQNDFO7wS6tZ4nrKxo43XCKB1A8nGIBFt2nXQ256P4Uf01dXV+x9c2kP/n9R6osPxxDr11GGCCRmWk+XDrCdHGPhVo8dJICJix3V5j3SwHTCad4OHfao6951tk2Kex6BPRFAF4NZQ/55pLcJdfFss73215+0a7udHui09beT/L66i67aFfCa3qYiNcTXV+dZQn1dJdd+r480hb5vrp1RV//6vfQ/c5ceu9BOr+ThAFwy3QuRc1cvL8EbiyVMDCziqSWpIK7V4dpH7QNACA9Y/+8YTioy91rYb48qH3QNgCAdKVxZvBE0osw3ZRUlFQb0L44YBuZ2ZqktTD7P2b2r9es79cl/fKa26aJukYzrXVJ01sbdY3mLtb1270a0giDfGx+cYj2QdsoXDq68eUjM6u7e+mm+xk36hrNtNYlTW9t1DWa+1ZXGo+ltiQtjNg+aBsAQIrSODPY18U7/YKkvSHa8wO2AQCkaOxnBu6+K6kQbgLnIzeF93q199omJdP6SSXqGs201iVNb23UNZp7VZd59OkOAMC9xFCWAADCAABwx8PAzCrhoba167RnWNdrM9szs6cZ1NXz5n3G/dWvron3l5nlzawYatvssc7E+2vIurL6+SqHf1PTX0PWlUl/RV5/Iv11Z8PgOk9CT0Ndwaq7r7j71iRq6gg38hNl+ZR4v7qCLPrrc0mlTm3xX8gM+6tvXcHE+8vMipKKoT+KZlaItWf1+9i3riCT30ep2w9Xakqjv+5sGKj9pHMzTHeeah6lPau6JCnf44cyS1n11zAm3l/uXo2MoVXQRd90ZNJfQ9QlZdNfDXffMrO8pKa7T0t/DapLyuj3MbxmUj1SCv11l8MgH5sf5knoSRjmdRcknZjZdvrlDC0fm59Ufw0js/4Kv7AnCR+HzsfmJ9pffeqSsv35Kkk6TFiej81P+uerV11Sdv1V6BFOUgr9dZfDoKXRn4SehIGvG97dtSS1OqeDU6ClKX1KPOP+qrj7esLylrLtr151ZdpfIZweJ7xuSxn2V5+6MukvMysPeN6qpTH3110Og+s8CT0JfV/XzNbCdcxpk1V/9ZVlf5lZpXMdOaGGzPqrX11Z9ZeZbUbuX7R09UCWSX8NqivDn6+TyIjOhUn8fN3ZMLjOk9DTUJekl2G+Ell/IkJNpei7n6z7a1Bdyqi/Qk2bZnZgZgcKB5Gs+2tQXcru52tbUjPSH52/Y5L1z1ffupRRf4V7GTW1///yneVp9hdPIAMA7u6ZAQBgeIQBAIAwAAAQBgAAEQYAABEGQKIw4Jub2WHk38EY999zYDQgC2n82Uvgrmi4+3LWRQCTwJkBMKLwVGrnwa7D6IiRZrbdeeArOrhZbHk+LC6EoZEPpmjYEdxTnBkAvRVjl4bqYbyfvKSyuy+HA/6BpA/CAX0hLC9K2pG0HIY7aIXla5KeqT18QNHdH4d97Eia2NPmQBxhAPTW7zLRC0ly96aZNcMBfSWyvBE5A1iR9Dws7wx3UJZUi+wjLyBDXCYC0rOQNB058LcmWQzQD2EAXM8XUvfA3hl3/iCyvKiLPz6yJ2k1LK9I4lNEmDpcJgJ6i98zkKTPwtdmaMsrHOjdvWpmy5Ft/iyyfCey/DO1/5gKMDUYtRQYkbX/MHpzksOLA2njMhEAgDMDAABnBgAAEQYAABEGAAARBgAAEQYAAEn/Dyn/p8oq3tpmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.plot(list(range(len(ll_tracking))), ll_tracking[\"NLL\"], label=\"Last-Layer\")\n",
    "axs.plot(list(range(len(full_vi_tracking))), full_vi_tracking[\"NLL\"], label=\"Full-Layer\")\n",
    "axs.legend()\n",
    "axs.set_xlabel(\"Epoch\")\n",
    "axs.set_ylabel(\"NLL\")\n",
    "axs.set_ylim(0, 0.25)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cabe5e2adc12bc55fec3b05872858fd36eca333f32d669b1230866c442273ae7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('DeepLearning': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
